\section{提案}
\subsection{missForestの概要}
missForestはランダムフォレストを基盤とした反復型の欠損補完手法である．各特徴量を目的変数とし，残りの特徴量を説明変数としてランダムフォレストを学習することで，欠損セルを逐次的に予測・更新する．これをすべての欠損列に対して繰り返し，推定値が収束するまで反復を行うことで最終的な補完結果を得る．この手法はすべての特徴量を一律に利用するため，ノイズ的な特徴量や寄与の小さい特徴量が予測精度を阻害する可能性がある．また高欠損率や高次元の状況では，精度劣化や過学習が生じやすいという課題を抱えている．

\subsection{手法の概要}
本研究で提案する手法は，欠損を含む各特徴量を目的変数とし，残りの特徴量を説明変数としてランダムフォレストを学習するという点ではmissForestと同様である．しかし，従来のmissForestが全ての特徴量を一律に利用するのに対し，提案法では複数の基準に基づいて「有効性の高い特徴量部分集合」を抽出し，各部分集合ごとに独立したランダムフォレストを学習させる．これにより，不要あるいはノイズ的な特徴量の影響を低減し，より頑健な予測を得ることを目的とする．

特徴量選択の基準としては，五つの方法を用いた．従来法と同様にすべての特徴量をそのまま利用する方法，Permutation Importanceに基づき寄与の大きい特徴量を抽出し，上位のみに限定する方法，ランダムフォレスト内部で得られるMean Decrease Impurityに基づき，分岐に寄与した重要な特徴量を選択する方法，欠損を含む対象特徴量と他の特徴量との相関係数を計算し，その絶対値が大きい特徴量を優先的に採用する方法，特徴量をランダムに抽出して部分集合を構築し，モデル間の多様性を確保する方法である．

このように異なる基準で抽出した部分集合により欠損値を予測することで，missForestに比べてノイズ的特徴量の利用による精度低下を抑制し，多様な視点からの補完が可能になる．

\subsection{アンサンブル統合}
各基準に基づく方法から得られた複数の予測値は，それぞれのモデルが持つ汎化性能に応じて重みづけし，最終的に加重平均することで統合する．本研究では重みとして，ランダムフォレストの外部誤差推定であるOOB $R^2$ を利用した．これは訓練に使用されなかったサンプルに対する決定係数であり，各部分モデルが未知データに対してどれだけ説明力を持つかを客観的に評価できる．

統合に際しては，OOB $R^2$ が高いモデルには大きな重みを，低いモデルには小さな重みを与えることで，信頼性の高い予測を優先的に反映する．一方で，ランダムに特徴量を選ぶ方法のように，OOB$R^2$ が必ずしも高くないモデルも一定の重みをもつため，多様な特徴選択によるバリエーションを保持できる．